{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import re\n",
    "from uuid import uuid4 as UUID\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given `patch-qualified-generations/logs-to-patch` contains a list of hashes to patch, run\n",
    "```shell\n",
    "cat patch-qualified-generations/logs-to-patch | sed -r 's/^hash:\\/\\/sha256\\/(\\w{2})(\\w{2})(\\w{60})/data\\/\\1\\/\\2\\/\\1\\2\\3/' > patch-qualified-generations/filepaths\n",
    "```\n",
    "to get the filepaths for the hashes. Then run\n",
    "```shell\n",
    "cat patch-qualified-generations/filepaths | xargs -L 1 python3 patch-qualified-generations.py > patch-qualified-generations/new-lines\n",
    "```\n",
    "\n",
    "to save the new qualified generations to `patch-qualified-generations/new-lines` in n-quads format.\n",
    "\n",
    "It takes a while.\n",
    "\n",
    "The dream was to pass `preston ls` to the script, but I couldn't decide on a safe way to prevent redundant generations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Value:\n",
    "    from enum import Enum\n",
    "    class Type(Enum):\n",
    "        ANY     = 0\n",
    "        CONTENT = 1\n",
    "        HASH    = CONTENT\n",
    "        UUID    = 2\n",
    "        URL     = 3\n",
    "        RAW     = 4\n",
    "\n",
    "    def __init__(self, text, valueType):\n",
    "        assert type(text) == str\n",
    "        assert type(valueType) == Value.Type\n",
    "        self.text = text\n",
    "        self.type = valueType\n",
    "    \n",
    "    def __lt__(self, other):\n",
    "        return str(self) < str(other)\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        t = type(other)\n",
    "        if   t == str:\n",
    "            return self.text == other\n",
    "        elif t == Value.Type:\n",
    "            return (other == Value.Type.ANY or self.type == other)\n",
    "        elif t == Value:\n",
    "            return (\n",
    "                self.text == other.text and\n",
    "                self.type == other.type\n",
    "            )\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.text\n",
    "    \n",
    "    def IsHash(self):\n",
    "        return self.type == Value.Type.CONTENT\n",
    "\n",
    "    def FromText(text):\n",
    "        if (re.match('^hash:\\/\\/sha256\\/.{64}$', text) or\n",
    "            re.match('^https?:\\/\\/.*\\.well-known\\/genid\\/\\w{8}-\\w{4}-\\w{4}-\\w{4}-\\w{12}$', text)):\n",
    "            type = Value.Type.CONTENT\n",
    "        elif re.match('^\\w{8}-\\w{4}-\\w{4}-\\w{4}-\\w{12}$', text):\n",
    "            type = Value.Type.UUID\n",
    "        elif re.match('^https?://', text):\n",
    "            type = Value.Type.URL\n",
    "        else:\n",
    "            type = Value.Type.RAW\n",
    "\n",
    "        return Value(text, type)\n",
    "\n",
    "class Verb:\n",
    "\n",
    "    def __init__(self, value):\n",
    "        assert type(value) == Value\n",
    "        self.value = value\n",
    "        self.triples = []\n",
    "    \n",
    "    def __lt__(self, other):\n",
    "        return str(self) < str(other)\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        t = type(other)\n",
    "        if  t == str:\n",
    "            return self.value == other\n",
    "        else:\n",
    "            return self.value == other.value\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.value.text\n",
    "\n",
    "    def Text(self):\n",
    "        return self.value.text\n",
    "\n",
    "    def FromText(text, index=None):\n",
    "        \"\"\"Returns a node associated with *text*\"\"\"\n",
    "        text = text.strip()\n",
    "        \n",
    "        # If the text is already indexed, use that\n",
    "        if index and text in index.verbLookup:\n",
    "            return index.verbLookup[text]\n",
    "\n",
    "        value = Value.FromText(text)\n",
    "        verb = Verb(value)\n",
    "\n",
    "        # Update the index\n",
    "        if index:\n",
    "            index.verbLookup[text] = verb\n",
    "            index.verbs.append(verb)\n",
    "\n",
    "        return verb\n",
    "\n",
    "class Node:\n",
    "\n",
    "    def __init__(self, value=None):\n",
    "        self.value = value\n",
    "        self.inwardTriples = []\n",
    "        self.outwardTriples = []\n",
    "    \n",
    "    def __lt__(self, other):\n",
    "        return str(self) < str(other)\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        t = type(other)\n",
    "        if  t == str:\n",
    "            return self.value == other\n",
    "        else:\n",
    "            return (\n",
    "                self.value == other.value\n",
    "            )\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.value.text\n",
    "\n",
    "    def Text(self):\n",
    "        return self.value.text\n",
    "\n",
    "    def Type(self):\n",
    "        return self.value.type\n",
    "\n",
    "    def IsHash(self):\n",
    "        return self.value.type == Value.Type.CONTENT\n",
    "\n",
    "    def FromText(text, index=None):\n",
    "        \"\"\"Returns a node associated with *text*\"\"\"\n",
    "        text = text.strip()\n",
    "        \n",
    "        # If the text is already indexed, use that\n",
    "        if index and text in index.nodeLookup:\n",
    "            return index.nodeLookup[text]\n",
    "\n",
    "        value = Value.FromText(text)\n",
    "        node = Node()\n",
    "        node.value = value\n",
    "\n",
    "        # Update the index\n",
    "        if index:\n",
    "            index.nodeLookup[text] = node\n",
    "            index.nodes.append(node)\n",
    "\n",
    "        return node\n",
    "\n",
    "class Triple:\n",
    "\n",
    "    def __init__(self, subject, verb, object):\n",
    "        assert type(subject) == Node\n",
    "        assert type(verb) == Verb\n",
    "        assert type(object) == Node\n",
    "        self.subject = subject\n",
    "        self.verb = verb\n",
    "        self.object = object\n",
    "    \n",
    "    def __lt__(self, other):\n",
    "        return str(self) < str(other)\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return (\n",
    "            self.subject    == other.subject    and\n",
    "            self.verb       == other.verb       and\n",
    "            self.object     == other.object\n",
    "        )\n",
    "\n",
    "    def __str__(self):\n",
    "        return str(self.subject) + '\\t' + str(self.verb) + '\\t' + str(self.object)\n",
    "\n",
    "    def Subject(self):\n",
    "        return parts[0]\n",
    "\n",
    "    def Verb(self):\n",
    "        return parts[1]\n",
    "\n",
    "    def Object(self):\n",
    "        return parts[2]\n",
    "\n",
    "    def Matches(self, subject=None, verb=None, object=None):\n",
    "        return (\n",
    "            (subject    == None or self.subject == subject  ) and\n",
    "            (verb       == None or self.verb    == verb     ) and\n",
    "            (object     == None or self.object  == object   )\n",
    "        )\n",
    "\n",
    "    def FromNQuad(nQuad, index=None):\n",
    "        \"\"\"Returns a triple extracted from *nQuad*\"\"\"\n",
    "\n",
    "        nQuadString = str(nQuad)\n",
    "\n",
    "        # If the text is already indexed, use that\n",
    "        if index and nQuadString in index.tripleLookup:\n",
    "            return index.tripleLookup[nQuadString]\n",
    "\n",
    "        subject = Node.FromText(nQuad[0][0], index)\n",
    "        verb = Verb.FromText(nQuad[1][0], index)\n",
    "        object = Node.FromText(nQuad[2][0], index)\n",
    "\n",
    "        triple = Triple(subject, verb, object)\n",
    "\n",
    "        # Make connections\n",
    "        subject.outwardTriples.append(triple)\n",
    "        object.inwardTriples.append(triple)\n",
    "        verb.triples.append(triple)\n",
    "\n",
    "        # Update the index\n",
    "        if index:\n",
    "            index.tripleLookup[nQuadString] = triple\n",
    "            index.triples.append(triple)\n",
    "\n",
    "        return triple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Index:\n",
    "    def __init__(self, nQuads):\n",
    "        self.nodeLookup = dict()\n",
    "        self.verbLookup = dict()\n",
    "        self.tripleLookup = dict()\n",
    "\n",
    "        self.nodes = list()\n",
    "        self.verbs = list()\n",
    "        self.triples = list()\n",
    "\n",
    "        # Parse n-quads\n",
    "        for nQuad in nQuads:\n",
    "            Triple.FromNQuad(nQuad, index=self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NQuads:\n",
    "    delimiters = {\n",
    "        '<' : '>',\n",
    "        '\"' : '\"'\n",
    "    }\n",
    "\n",
    "    # TODO: retain the \"@en\" flag on text values\n",
    "    def Parse(text):\n",
    "        nquads = []\n",
    "        groups = []\n",
    "        inGroup = False\n",
    "        subgroupStart = None\n",
    "        subgroups = []\n",
    "        delimiter = ''\n",
    "        for i, c in enumerate(text):\n",
    "            if inGroup:\n",
    "                if c == delimiter:\n",
    "                    subgroup = text[subgroupStart : i]\n",
    "                    subgroups.append(subgroup)\n",
    "                    delimiter = ''\n",
    "                elif delimiter == '':\n",
    "                    # Treat back-to-back delimiters as one group\n",
    "                    if c in NQuads.delimiters:\n",
    "                        delimiter = NQuads.delimiters[c]\n",
    "                        subgroupStart = i + 1\n",
    "                    # Spaces only end the group when outside a pair of delimiters\n",
    "                    elif c.isspace():\n",
    "                        groups.append(tuple(subgroups))\n",
    "                        inGroup = False\n",
    "                        subgroups = []\n",
    "            else:\n",
    "                if c == '.':\n",
    "                    nquads.append(groups)\n",
    "                    groups = []\n",
    "                elif c in NQuads.delimiters:\n",
    "                    delimiter = NQuads.delimiters[c]\n",
    "                    subgroupStart = i + 1\n",
    "                    inGroup = True\n",
    "        return nquads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('https://preston.guoda.bio',),\n",
       "  ('http://purl.org/dc/terms/description',),\n",
       "  ('Preston is a software program that finds, archives and provides access to biodiversity datasets.',)]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NQuads.Parse('<https://preston.guoda.bio> <http://purl.org/dc/terms/description> \"Preston is a software program that finds, archives and provides access to biodiversity datasets.\"@en .')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('https://idigbio.org',),\n",
       "  ('http://www.w3.org/ns/prov#wasAssociatedWith',),\n",
       "  ('daf3ee3f-8f3e-495e-b57f-bc93c8fccb2c',)]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NQuads.Parse('<https://idigbio.org> <http://www.w3.org/ns/prov#wasAssociatedWith> <daf3ee3f-8f3e-495e-b57f-bc93c8fccb2c> .')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('hash://sha256/844e59241f5d0f44891ce46ea1816394baf49184698005c66de73e6163d49d3b',),\n",
       "  ('http://www.w3.org/ns/prov#generatedAtTime',),\n",
       "  ('2019-02-04T16:34:10.865Z', 'http://www.w3.org/2001/XMLSchema#dateTime')]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NQuads.Parse('<hash://sha256/844e59241f5d0f44891ce46ea1816394baf49184698005c66de73e6163d49d3b> <http://www.w3.org/ns/prov#generatedAtTime> \"2019-02-04T16:34:10.865Z\"^^<http://www.w3.org/2001/XMLSchema#dateTime> .')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../preston.acis.ufl.edu/data/05/a8/05a877bdb8617144fe166a13bf51828d4ad1bc11631c360b9e648a9f7df2bbcd\"\n",
    "path = \"../preston.acis.ufl.edu/data/20/d3/20d36a6f879ba1dd797d4288a4f2e32719d3c674156194c2765a3ec6b43f5e17\"\n",
    "\n",
    "allNQuads = []\n",
    "with codecs.open(path, 'r', encoding='utf-8', errors='ignore') as file:\n",
    "    nQuads = NQuads.Parse(file.read())\n",
    "    allNQuads += nQuads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullIndex = Index(allNQuads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List verbs read from the ingested logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://purl.org/dc/elements/1.1/format\n",
      "http://purl.org/dc/terms/description\n",
      "http://purl.org/pav/createdBy\n",
      "http://purl.org/pav/hasVersion\n",
      "http://purl.org/pav/previousVersion\n",
      "http://www.w3.org/1999/02/22-rdf-syntax-ns#type\n",
      "http://www.w3.org/ns/prov#generatedAtTime\n",
      "http://www.w3.org/ns/prov#hadMember\n",
      "http://www.w3.org/ns/prov#startedAtTime\n",
      "http://www.w3.org/ns/prov#usedBy\n",
      "http://www.w3.org/ns/prov#wasAssociatedWith\n",
      "http://www.w3.org/ns/prov#wasGeneratedBy\n",
      "http://www.w3.org/ns/prov#wasStartedBy\n"
     ]
    }
   ],
   "source": [
    "for x in sorted(fullIndex.verbs): print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the UUID of the crawl activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e871efcd-c2f9-4e8e-ac3a-bc45943c3e65\n"
     ]
    }
   ],
   "source": [
    "crawlNode = None\n",
    "for t in fullIndex.verbLookup[\"http://www.w3.org/1999/02/22-rdf-syntax-ns#type\"].triples:\n",
    "    if t.object == \"http://www.w3.org/ns/prov#Activity\":\n",
    "        crawlNode = t.subject\n",
    "        break\n",
    "crawlUUID = str(crawlNode)\n",
    "print(crawlUUID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://search.idigbio.org/v2/search/publishers\thttp://purl.org/pav/hasVersion\thash://sha256/3eff98d4b66368fd8d1f8fa1af6a057774d8a407a4771490beeb9e7add76f362\n",
      "https://api.gbif.org/v1/dataset\thttp://purl.org/pav/hasVersion\thash://sha256/184886cc6ae4490a49a70b6fd9a3e1dfafce433fc8e3d022c89e0b75ea3cda0b\n",
      "https://bms.gfbio.org/services/data-sources/\thttp://purl.org/pav/hasVersion\thash://sha256/ba4f1de1f97ef57c90d321b7bf36426ac4031fa3a312af2c22a538d0f4387a4c\n"
     ]
    }
   ],
   "source": [
    "exampleQuery = [\n",
    "    x for x in fullIndex.triples if (\n",
    "        x.subject.Type() == Value.Type.URL and\n",
    "        x.verb == \"http://purl.org/pav/hasVersion\" and\n",
    "        x.object.Type() == Value.Type.CONTENT\n",
    "    )\n",
    "]\n",
    "\n",
    "for triple in exampleQuery[:3]:\n",
    "    print(triple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To construct qualified generations from past logs:\n",
    "1. Start at (`URL hasVersion HASH`)\n",
    "1. Collect (`HASH X Y`) triples that follow\n",
    "1. Follow the `previousVersion` chain in reverse to find the actual content generated by the crawl (the \"latest version\")\n",
    "\n",
    "NOTE: recursively following the `previousVersion` chain doesn't always work since sometimes it's circular. Infinite recursion ensues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def GetLatestVersion(node):\n",
    "#     previousVersions = [x for x in node.inwardTriples if x.verb == \"http://purl.org/pav/previousVersion\"]\n",
    "#     if len(previousVersions) > 0:\n",
    "#         return GetLatestVersion(previousVersions[0].subject)\n",
    "#     else:\n",
    "#         return node\n",
    "\n",
    "# def MakeQualifiedGeneration(url, context, crawlUUID):\n",
    "#     index = Index(context)\n",
    "\n",
    "#     urlNode = index.nodeLookup[url]\n",
    "#     firstVersion = [x for x in urlNode.outwardTriples if x.verb == \"http://purl.org/pav/hasVersion\"][0].object\n",
    "#     latestVersion = GetLatestVersion(firstVersion)\n",
    "    \n",
    "#     qualGenUUID = UUID()\n",
    "\n",
    "#     newLines = [\n",
    "#         \"<%s> <%s> <%s> .\" % \\\n",
    "#             (str(latestVersion), \"http://www.w3.org/ns/prov#qualifiedGeneration\", str(qualGenUUID)),\n",
    "\n",
    "#         \"<%s> <%s> <%s> .\" % \\\n",
    "#             (str(qualGenUUID), \"http://www.w3.org/1999/02/22-rdf-syntax-ns#type\", \"http://www.w3.org/ns/prov#Generation\"),\n",
    "\n",
    "#         \"<%s> <%s> <%s> .\" % \\\n",
    "#             (str(qualGenUUID), \"http://www.w3.org/ns/prov#activity\", str(crawlUUID)),\n",
    "\n",
    "#         \"<%s> <%s> <%s> .\" % \\\n",
    "#             (str(qualGenUUID), \"http://www.w3.org/ns/prov#used\", str(url)),\n",
    "#     ]\n",
    "    \n",
    "#     return newLines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, let's assume the version furthest down the list of n-quads is the most recent. Is this a safe assumption?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PrintQualifiedGeneration(url, latestVersion, crawlUUID):\n",
    "    qualGenUUID = UUID()\n",
    "\n",
    "    print(\"<%s> <%s> <%s> .\" %\n",
    "        (str(latestVersion), \"http://www.w3.org/ns/prov#qualifiedGeneration\", str(qualGenUUID))\n",
    "    )\n",
    "\n",
    "    print(\"<%s> <%s> <%s> .\" %\n",
    "        (str(qualGenUUID), \"http://www.w3.org/1999/02/22-rdf-syntax-ns#type\", \"http://www.w3.org/ns/prov#Generation\")\n",
    "    )\n",
    "    \n",
    "    print(\"<%s> <%s> <%s> .\" %\n",
    "        (str(qualGenUUID), \"http://www.w3.org/ns/prov#activity\", str(crawlUUID))\n",
    "    )\n",
    "\n",
    "    print(\"<%s> <%s> <%s> .\" %\n",
    "        (str(qualGenUUID), \"http://www.w3.org/ns/prov#used\", str(url)),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import io\n",
    "\n",
    "path = \"../preston.acis.ufl.edu/data/20/d3/20d36a6f879ba1dd797d4288a4f2e32719d3c674156194c2765a3ec6b43f5e17\"\n",
    "\n",
    "file = open(path, \"r\")\n",
    "sys.stdin = io.StringIO(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<hash://sha256/d8abe764baa8807af8c8f5034157945937fdaec9002a7b975df429d7538c4897> <http://www.w3.org/ns/prov#qualifiedGeneration> <b8933518-3351-4299-a713-7538606dd7e7> .\n",
      "<b8933518-3351-4299-a713-7538606dd7e7> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/ns/prov#Generation> .\n",
      "<b8933518-3351-4299-a713-7538606dd7e7> <http://www.w3.org/ns/prov#activity> <e871efcd-c2f9-4e8e-ac3a-bc45943c3e65> .\n",
      "<b8933518-3351-4299-a713-7538606dd7e7> <http://www.w3.org/ns/prov#used> <https://api.gbif.org/v1/dataset> .\n"
     ]
    }
   ],
   "source": [
    "url = None\n",
    "latestVersion = None\n",
    "crawlUUID = None\n",
    "didOne = False\n",
    "for line in sys.stdin:\n",
    "    nQuads = NQuads.Parse(line)\n",
    "    for nQuad in nQuads:\n",
    "        triple = Triple.FromNQuad(nQuad)\n",
    "\n",
    "        # Watch for newer versions for the current URL\n",
    "        if (\n",
    "            triple.subject.Type() == Value.Type.CONTENT and\n",
    "            triple.verb == \"http://purl.org/pav/previousVersion\" and\n",
    "            triple.object.Type() == Value.Type.CONTENT\n",
    "        ):\n",
    "            latestVersion = str(triple.subject)\n",
    "        # Watch for existing qualified generations\n",
    "        elif (\n",
    "            triple.subject.Type() == Value.Type.CONTENT and\n",
    "            triple.verb == \"http://www.w3.org/ns/prov#qualifiedGeneration\" and\n",
    "            triple.object.Type() == Value.Type.UUID\n",
    "        ):\n",
    "            # No need to log a new download event\n",
    "            url = None\n",
    "        # Check for the start of a download event\n",
    "        elif (\n",
    "            crawlUUID and\n",
    "            triple.subject.Type() == Value.Type.URL and\n",
    "            triple.verb == \"http://purl.org/pav/hasVersion\" and\n",
    "            triple.object.Type() == Value.Type.CONTENT\n",
    "        ):\n",
    "            # Create a generation for the previous\n",
    "            if url and latestVersion:\n",
    "                PrintQualifiedGeneration(url, latestVersion, crawlUUID)\n",
    "                didOne = True\n",
    "\n",
    "            # Start reading triples for the next URL\n",
    "            url = str(triple.subject)\n",
    "            latestVersion = None\n",
    "        # Check for a new crawl UUID\n",
    "        elif triple.object == \"http://www.w3.org/ns/prov#Activity\":\n",
    "            crawlUUID = str(triple.subject)\n",
    "            url = None\n",
    "    if didOne:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
