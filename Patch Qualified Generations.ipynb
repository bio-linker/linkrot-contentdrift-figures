{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import re\n",
    "from uuid import uuid4 as UUID\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given `patch-qualified-generations/logs-to-patch` contains a list of hashes to patch, run\n",
    "```shell\n",
    "cat patch-qualified-generations/logs-to-patch | sed -r 's/^hash:\\/\\/sha256\\/(\\w{2})(\\w{2})(\\w{60})/data\\/\\1\\/\\2\\/\\1\\2\\3/' > patch-qualified-generations/filepaths\n",
    "```\n",
    "to get the filepaths for the hashes. Then run\n",
    "```shell\n",
    "cat patch-qualified-generations/filepaths | xargs -L 1 python3 patch-qualified-generations.py > patch-qualified-generations/new-lines\n",
    "```\n",
    "\n",
    "to save the new qualified generations to `patch-qualified-generations/new-lines` in n-quads format.\n",
    "\n",
    "It takes a while.\n",
    "\n",
    "The dream was to pass `preston ls` to the script, but I couldn't decide on a safe way to prevent redundant generations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Value:\n",
    "    from enum import Enum\n",
    "    class Type(Enum):\n",
    "        ANY     = 0\n",
    "        CONTENT = 1\n",
    "        HASH    = CONTENT\n",
    "        UUID    = 2\n",
    "        URL     = 3\n",
    "        RAW     = 4\n",
    "\n",
    "    def __init__(self, text, valueType):\n",
    "        assert type(text) == str\n",
    "        assert type(valueType) == Value.Type\n",
    "        self.text = text\n",
    "        self.type = valueType\n",
    "    \n",
    "    def __lt__(self, other):\n",
    "        return str(self) < str(other)\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        t = type(other)\n",
    "        if   t == str:\n",
    "            return self.text == other\n",
    "        elif t == Value.Type:\n",
    "            return (other == Value.Type.ANY or self.type == other)\n",
    "        elif t == Value:\n",
    "            return (\n",
    "                self.text == other.text and\n",
    "                self.type == other.type\n",
    "            )\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.text\n",
    "    \n",
    "    def IsHash(self):\n",
    "        return self.type == Value.Type.CONTENT\n",
    "\n",
    "    def FromText(text):\n",
    "        if (re.match('^hash:\\/\\/sha256\\/.{64}$', text) or\n",
    "            re.match('^https?:\\/\\/.*\\.well-known\\/genid\\/\\w{8}-\\w{4}-\\w{4}-\\w{4}-\\w{12}$', text)):\n",
    "            type = Value.Type.CONTENT\n",
    "        elif re.match('^\\w{8}-\\w{4}-\\w{4}-\\w{4}-\\w{12}$', text):\n",
    "            type = Value.Type.UUID\n",
    "        elif re.match('^https?://', text):\n",
    "            type = Value.Type.URL\n",
    "        else:\n",
    "            type = Value.Type.RAW\n",
    "\n",
    "        return Value(text, type)\n",
    "\n",
    "class Verb:\n",
    "\n",
    "    def __init__(self, value):\n",
    "        assert type(value) == Value\n",
    "        self.value = value\n",
    "        self.triples = []\n",
    "    \n",
    "    def __lt__(self, other):\n",
    "        return str(self) < str(other)\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        t = type(other)\n",
    "        if  t == str:\n",
    "            return self.value == other\n",
    "        else:\n",
    "            return self.value == other.value\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.value.text\n",
    "\n",
    "    def Text(self):\n",
    "        return self.value.text\n",
    "\n",
    "    def FromText(text, index=None):\n",
    "        \"\"\"Returns a node associated with *text*\"\"\"\n",
    "        text = text.strip()\n",
    "        \n",
    "        # If the text is already indexed, use that\n",
    "        if index and text in index.verbLookup:\n",
    "            return index.verbLookup[text]\n",
    "\n",
    "        value = Value.FromText(text)\n",
    "        verb = Verb(value)\n",
    "\n",
    "        # Update the index\n",
    "        if index:\n",
    "            index.verbLookup[text] = verb\n",
    "            index.verbs.append(verb)\n",
    "\n",
    "        return verb\n",
    "\n",
    "class Node:\n",
    "\n",
    "    def __init__(self, value=None):\n",
    "        self.value = value\n",
    "        self.inwardTriples = []\n",
    "        self.outwardTriples = []\n",
    "    \n",
    "    def __lt__(self, other):\n",
    "        return str(self) < str(other)\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        t = type(other)\n",
    "        if  t == str:\n",
    "            return self.value == other\n",
    "        else:\n",
    "            return (\n",
    "                self.value == other.value\n",
    "            )\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.value.text\n",
    "\n",
    "    def Text(self):\n",
    "        return self.value.text\n",
    "\n",
    "    def Type(self):\n",
    "        return self.value.type\n",
    "\n",
    "    def IsHash(self):\n",
    "        return self.value.type == Value.Type.CONTENT\n",
    "\n",
    "    def FromText(text, index=None):\n",
    "        \"\"\"Returns a node associated with *text*\"\"\"\n",
    "        text = text.strip()\n",
    "        \n",
    "        # If the text is already indexed, use that\n",
    "        if index and text in index.nodeLookup:\n",
    "            return index.nodeLookup[text]\n",
    "\n",
    "        value = Value.FromText(text)\n",
    "        node = Node()\n",
    "        node.value = value\n",
    "\n",
    "        # Update the index\n",
    "        if index:\n",
    "            index.nodeLookup[text] = node\n",
    "            index.nodes.append(node)\n",
    "\n",
    "        return node\n",
    "\n",
    "class Triple:\n",
    "\n",
    "    def __init__(self, subject, verb, object):\n",
    "        assert type(subject) == Node\n",
    "        assert type(verb) == Verb\n",
    "        assert type(object) == Node\n",
    "        self.subject = subject\n",
    "        self.verb = verb\n",
    "        self.object = object\n",
    "    \n",
    "    def __lt__(self, other):\n",
    "        return str(self) < str(other)\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return (\n",
    "            self.subject    == other.subject    and\n",
    "            self.verb       == other.verb       and\n",
    "            self.object     == other.object\n",
    "        )\n",
    "\n",
    "    def __str__(self):\n",
    "        return str(self.subject) + '\\t' + str(self.verb) + '\\t' + str(self.object)\n",
    "\n",
    "    def Subject(self):\n",
    "        return parts[0]\n",
    "\n",
    "    def Verb(self):\n",
    "        return parts[1]\n",
    "\n",
    "    def Object(self):\n",
    "        return parts[2]\n",
    "\n",
    "    def Matches(self, subject=None, verb=None, object=None):\n",
    "        return (\n",
    "            (subject    == None or self.subject == subject  ) and\n",
    "            (verb       == None or self.verb    == verb     ) and\n",
    "            (object     == None or self.object  == object   )\n",
    "        )\n",
    "\n",
    "    def FromNQuad(nQuad, index=None):\n",
    "        \"\"\"Returns a triple extracted from *nQuad*\"\"\"\n",
    "\n",
    "        nQuadString = str(nQuad)\n",
    "\n",
    "        # If the text is already indexed, use that\n",
    "        if index and nQuadString in index.tripleLookup:\n",
    "            return index.tripleLookup[nQuadString]\n",
    "\n",
    "        subject = Node.FromText(nQuad[0][0], index)\n",
    "        verb = Verb.FromText(nQuad[1][0], index)\n",
    "        object = Node.FromText(nQuad[2][0], index)\n",
    "\n",
    "        triple = Triple(subject, verb, object)\n",
    "\n",
    "        # Make connections\n",
    "        subject.outwardTriples.append(triple)\n",
    "        object.inwardTriples.append(triple)\n",
    "        verb.triples.append(triple)\n",
    "\n",
    "        # Update the index\n",
    "        if index:\n",
    "            index.tripleLookup[nQuadString] = triple\n",
    "            index.triples.append(triple)\n",
    "\n",
    "        return triple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Index:\n",
    "    def __init__(self, nQuads):\n",
    "        self.nodeLookup = dict()\n",
    "        self.verbLookup = dict()\n",
    "        self.tripleLookup = dict()\n",
    "\n",
    "        self.nodes = list()\n",
    "        self.verbs = list()\n",
    "        self.triples = list()\n",
    "\n",
    "        # Parse n-quads\n",
    "        for nQuad in nQuads:\n",
    "            Triple.FromNQuad(nQuad, index=self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NQuads:\n",
    "    delimiters = {\n",
    "        '<' : '>',\n",
    "        '\"' : '\"'\n",
    "    }\n",
    "\n",
    "    # TODO: retain the \"@en\" flag on text values\n",
    "    def Parse(text):\n",
    "        nquads = []\n",
    "        groups = []\n",
    "        inGroup = False\n",
    "        subgroupStart = None\n",
    "        subgroups = []\n",
    "        delimiter = ''\n",
    "        for i, c in enumerate(text):\n",
    "            if inGroup:\n",
    "                if c == delimiter:\n",
    "                    subgroup = text[subgroupStart : i]\n",
    "                    subgroups.append(subgroup)\n",
    "                    delimiter = ''\n",
    "                elif delimiter == '':\n",
    "                    # Treat back-to-back delimiters as one group\n",
    "                    if c in NQuads.delimiters:\n",
    "                        delimiter = NQuads.delimiters[c]\n",
    "                        subgroupStart = i + 1\n",
    "                    # Spaces only end the group when outside a pair of delimiters\n",
    "                    elif c.isspace():\n",
    "                        groups.append(tuple(subgroups))\n",
    "                        inGroup = False\n",
    "                        subgroups = []\n",
    "            else:\n",
    "                if c == '.':\n",
    "                    nquads.append(groups)\n",
    "                    groups = []\n",
    "                elif c in NQuads.delimiters:\n",
    "                    delimiter = NQuads.delimiters[c]\n",
    "                    subgroupStart = i + 1\n",
    "                    inGroup = True\n",
    "        return nquads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('https://preston.guoda.bio',),\n",
       "  ('http://purl.org/dc/terms/description',),\n",
       "  ('Preston is a software program that finds, archives and provides access to biodiversity datasets.',)]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NQuads.Parse('<https://preston.guoda.bio> <http://purl.org/dc/terms/description> \"Preston is a software program that finds, archives and provides access to biodiversity datasets.\"@en .')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('https://idigbio.org',),\n",
       "  ('http://www.w3.org/ns/prov#wasAssociatedWith',),\n",
       "  ('daf3ee3f-8f3e-495e-b57f-bc93c8fccb2c',)]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NQuads.Parse('<https://idigbio.org> <http://www.w3.org/ns/prov#wasAssociatedWith> <daf3ee3f-8f3e-495e-b57f-bc93c8fccb2c> .')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('hash://sha256/844e59241f5d0f44891ce46ea1816394baf49184698005c66de73e6163d49d3b',),\n",
       "  ('http://www.w3.org/ns/prov#generatedAtTime',),\n",
       "  ('2019-02-04T16:34:10.865Z', 'http://www.w3.org/2001/XMLSchema#dateTime')]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NQuads.Parse('<hash://sha256/844e59241f5d0f44891ce46ea1816394baf49184698005c66de73e6163d49d3b> <http://www.w3.org/ns/prov#generatedAtTime> \"2019-02-04T16:34:10.865Z\"^^<http://www.w3.org/2001/XMLSchema#dateTime> .')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/05/a8/05a877bdb8617144fe166a13bf51828d4ad1bc11631c360b9e648a9f7df2bbcd\"\n",
    "path = \"data/20/d3/20d36a6f879ba1dd797d4288a4f2e32719d3c674156194c2765a3ec6b43f5e17\"\n",
    "\n",
    "allNQuads = []\n",
    "with codecs.open(path, 'r', encoding='utf-8', errors='ignore') as file:\n",
    "    nQuads = NQuads.Parse(file.read())\n",
    "    allNQuads += nQuads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullIndex = Index(allNQuads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List verbs read from the ingested logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://purl.org/dc/elements/1.1/format\n",
      "http://purl.org/dc/terms/description\n",
      "http://purl.org/pav/createdBy\n",
      "http://purl.org/pav/hasVersion\n",
      "http://purl.org/pav/previousVersion\n",
      "http://www.w3.org/1999/02/22-rdf-syntax-ns#type\n",
      "http://www.w3.org/ns/prov#generatedAtTime\n",
      "http://www.w3.org/ns/prov#hadMember\n",
      "http://www.w3.org/ns/prov#startedAtTime\n",
      "http://www.w3.org/ns/prov#usedBy\n",
      "http://www.w3.org/ns/prov#wasAssociatedWith\n",
      "http://www.w3.org/ns/prov#wasGeneratedBy\n",
      "http://www.w3.org/ns/prov#wasStartedBy\n"
     ]
    }
   ],
   "source": [
    "for x in sorted(fullIndex.verbs): print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the UUID of the crawl activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e871efcd-c2f9-4e8e-ac3a-bc45943c3e65\n"
     ]
    }
   ],
   "source": [
    "crawlNode = None\n",
    "for t in fullIndex.verbLookup[\"http://www.w3.org/1999/02/22-rdf-syntax-ns#type\"].triples:\n",
    "    if t.object == \"http://www.w3.org/ns/prov#Activity\":\n",
    "        crawlNode = t.subject\n",
    "        break\n",
    "crawlUUID = str(crawlNode)\n",
    "print(crawlUUID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://search.idigbio.org/v2/search/publishers\thttp://purl.org/pav/hasVersion\thash://sha256/3eff98d4b66368fd8d1f8fa1af6a057774d8a407a4771490beeb9e7add76f362\n",
      "https://api.gbif.org/v1/dataset\thttp://purl.org/pav/hasVersion\thash://sha256/184886cc6ae4490a49a70b6fd9a3e1dfafce433fc8e3d022c89e0b75ea3cda0b\n",
      "https://bms.gfbio.org/services/data-sources/\thttp://purl.org/pav/hasVersion\thash://sha256/ba4f1de1f97ef57c90d321b7bf36426ac4031fa3a312af2c22a538d0f4387a4c\n"
     ]
    }
   ],
   "source": [
    "exampleQuery = [\n",
    "    x for x in fullIndex.triples if (\n",
    "        x.subject.Type() == Value.Type.URL and\n",
    "        x.verb == \"http://purl.org/pav/hasVersion\" and\n",
    "        x.object.Type() == Value.Type.CONTENT\n",
    "    )\n",
    "]\n",
    "\n",
    "for triple in exampleQuery[:3]:\n",
    "    print(triple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To construct qualified generations from past logs:\n",
    "1. Start at (`URL hasVersion HASH`)\n",
    "1. Collect (`HASH X Y`) triples that follow\n",
    "1. Follow the `previousVersion` chain in reverse to find the actual content generated by the crawl (the \"latest version\")\n",
    "\n",
    "NOTE: recursively following the `previousVersion` chain doesn't always work since sometimes it's circular. Infinite recursion ensues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def GetLatestVersion(node):\n",
    "#     previousVersions = [x for x in node.inwardTriples if x.verb == \"http://purl.org/pav/previousVersion\"]\n",
    "#     if len(previousVersions) > 0:\n",
    "#         return GetLatestVersion(previousVersions[0].subject)\n",
    "#     else:\n",
    "#         return node\n",
    "\n",
    "# def MakeQualifiedGeneration(url, context, crawlUUID):\n",
    "#     index = Index(context)\n",
    "\n",
    "#     urlNode = index.nodeLookup[url]\n",
    "#     firstVersion = [x for x in urlNode.outwardTriples if x.verb == \"http://purl.org/pav/hasVersion\"][0].object\n",
    "#     latestVersion = GetLatestVersion(firstVersion)\n",
    "    \n",
    "#     qualGenUUID = UUID()\n",
    "\n",
    "#     newLines = [\n",
    "#         \"<%s> <%s> <%s> .\" % \\\n",
    "#             (str(latestVersion), \"http://www.w3.org/ns/prov#qualifiedGeneration\", str(qualGenUUID)),\n",
    "\n",
    "#         \"<%s> <%s> <%s> .\" % \\\n",
    "#             (str(qualGenUUID), \"http://www.w3.org/1999/02/22-rdf-syntax-ns#type\", \"http://www.w3.org/ns/prov#Generation\"),\n",
    "\n",
    "#         \"<%s> <%s> <%s> .\" % \\\n",
    "#             (str(qualGenUUID), \"http://www.w3.org/ns/prov#activity\", str(crawlUUID)),\n",
    "\n",
    "#         \"<%s> <%s> <%s> .\" % \\\n",
    "#             (str(qualGenUUID), \"http://www.w3.org/ns/prov#used\", str(url)),\n",
    "#     ]\n",
    "    \n",
    "#     return newLines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, let's assume the version furthest down the list of n-quads is the most recent. Is this a safe assumption?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MakeQualifiedGeneration(url, context, crawlUUID):\n",
    "    # The first line is always a `hasVersion` statement; default to this version if no other exists\n",
    "    latestVersion = Triple.FromNQuad(context[0]).object\n",
    "    for nQuad in context:\n",
    "        triple = Triple.FromNQuad(nQuad)\n",
    "        if (\n",
    "            triple.subject.Type() == Value.Type.CONTENT and\n",
    "            triple.verb == \"http://purl.org/pav/previousVersion\" and\n",
    "            triple.object.Type() == Value.Type.CONTENT\n",
    "        ):\n",
    "            latestVersion = triple.subject\n",
    "\n",
    "    qualGenUUID = UUID()\n",
    "\n",
    "    newLines = [\n",
    "        \"<%s> <%s> <%s> .\" % \\\n",
    "            (str(latestVersion), \"http://www.w3.org/ns/prov#qualifiedGeneration\", str(qualGenUUID)),\n",
    "\n",
    "        \"<%s> <%s> <%s> .\" % \\\n",
    "            (str(qualGenUUID), \"http://www.w3.org/1999/02/22-rdf-syntax-ns#type\", \"http://www.w3.org/ns/prov#Generation\"),\n",
    "\n",
    "        \"<%s> <%s> <%s> .\" % \\\n",
    "            (str(qualGenUUID), \"http://www.w3.org/ns/prov#activity\", str(crawlUUID)),\n",
    "\n",
    "        \"<%s> <%s> <%s> .\" % \\\n",
    "            (str(qualGenUUID), \"http://www.w3.org/ns/prov#used\", str(url)),\n",
    "    ]\n",
    "    \n",
    "    return newLines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://ipt.gbifbenin.org/archive.do?r=cnsf_niger\thttp://purl.org/pav/hasVersion\thash://sha256/d981008d7c7dddd827bcba16087a9c88cf233567d4751f67bb7f96e0756f2c9c\n",
      "https://deeplinker.bio/.well-known/genid/8f10765c-ed12-3d2a-9d09-0beda4008639\thttp://www.w3.org/ns/prov#generatedAtTime\t2018-09-03T02:19:17.229Z\n",
      "https://deeplinker.bio/.well-known/genid/8f10765c-ed12-3d2a-9d09-0beda4008639\thttp://purl.org/pav/previousVersion\thash://sha256/d981008d7c7dddd827bcba16087a9c88cf233567d4751f67bb7f96e0756f2c9c\n",
      "https://deeplinker.bio/.well-known/genid/5419db5d-2589-3ab9-be1e-31392f150ffd\thttp://www.w3.org/ns/prov#generatedAtTime\t2018-09-04T07:10:13.672Z\n",
      "https://deeplinker.bio/.well-known/genid/5419db5d-2589-3ab9-be1e-31392f150ffd\thttp://purl.org/pav/previousVersion\thttps://deeplinker.bio/.well-known/genid/8f10765c-ed12-3d2a-9d09-0beda4008639\n",
      "https://deeplinker.bio/.well-known/genid/ec114320-b4a9-3e5a-8280-ccfb2214a9bd\thttp://www.w3.org/ns/prov#generatedAtTime\t2018-09-04T07:20:10.255Z\n",
      "https://deeplinker.bio/.well-known/genid/ec114320-b4a9-3e5a-8280-ccfb2214a9bd\thttp://purl.org/pav/previousVersion\thttps://deeplinker.bio/.well-known/genid/5419db5d-2589-3ab9-be1e-31392f150ffd\n",
      "https://deeplinker.bio/.well-known/genid/fc090d11-86e2-3df5-9aed-2158fb1ac9c1\thttp://www.w3.org/ns/prov#generatedAtTime\t2018-09-04T07:22:22.181Z\n",
      "https://deeplinker.bio/.well-known/genid/fc090d11-86e2-3df5-9aed-2158fb1ac9c1\thttp://purl.org/pav/previousVersion\thttps://deeplinker.bio/.well-known/genid/ec114320-b4a9-3e5a-8280-ccfb2214a9bd\n",
      "https://deeplinker.bio/.well-known/genid/e9fb5779-0ffd-3292-a300-2136a3f696f3\thttp://www.w3.org/ns/prov#generatedAtTime\t2018-09-04T07:28:35.219Z\n",
      "https://deeplinker.bio/.well-known/genid/e9fb5779-0ffd-3292-a300-2136a3f696f3\thttp://purl.org/pav/previousVersion\thttps://deeplinker.bio/.well-known/genid/fc090d11-86e2-3df5-9aed-2158fb1ac9c1\n",
      "https://deeplinker.bio/.well-known/genid/c1a1c72f-52ca-32bf-80aa-93e8b0456ac6\thttp://www.w3.org/ns/prov#generatedAtTime\t2018-09-04T07:32:01.115Z\n",
      "https://deeplinker.bio/.well-known/genid/c1a1c72f-52ca-32bf-80aa-93e8b0456ac6\thttp://purl.org/pav/previousVersion\thttps://deeplinker.bio/.well-known/genid/e9fb5779-0ffd-3292-a300-2136a3f696f3\n",
      "https://deeplinker.bio/.well-known/genid/e8cb7ca0-e242-3a26-997d-c7a4cc1d7565\thttp://www.w3.org/ns/prov#generatedAtTime\t2018-09-04T20:49:47.379Z\n",
      "https://deeplinker.bio/.well-known/genid/e8cb7ca0-e242-3a26-997d-c7a4cc1d7565\thttp://purl.org/pav/previousVersion\thttps://deeplinker.bio/.well-known/genid/c1a1c72f-52ca-32bf-80aa-93e8b0456ac6\n",
      "https://deeplinker.bio/.well-known/genid/20e4f28d-4784-3fa6-b204-e17b37906877\thttp://www.w3.org/ns/prov#generatedAtTime\t2018-09-05T07:32:44.259Z\n",
      "https://deeplinker.bio/.well-known/genid/20e4f28d-4784-3fa6-b204-e17b37906877\thttp://purl.org/pav/previousVersion\thttps://deeplinker.bio/.well-known/genid/e8cb7ca0-e242-3a26-997d-c7a4cc1d7565\n",
      "https://deeplinker.bio/.well-known/genid/1ef911be-b73f-3aee-99a2-046342615d46\thttp://www.w3.org/ns/prov#generatedAtTime\t2018-09-07T19:06:39.275Z\n",
      "https://deeplinker.bio/.well-known/genid/1ef911be-b73f-3aee-99a2-046342615d46\thttp://purl.org/pav/previousVersion\thttps://deeplinker.bio/.well-known/genid/20e4f28d-4784-3fa6-b204-e17b37906877\n",
      "hash://sha256/d981008d7c7dddd827bcba16087a9c88cf233567d4751f67bb7f96e0756f2c9c\thttp://www.w3.org/ns/prov#generatedAtTime\t2018-08-31T18:40:32.789Z\n",
      "hash://sha256/d981008d7c7dddd827bcba16087a9c88cf233567d4751f67bb7f96e0756f2c9c\thttp://purl.org/pav/previousVersion\thttps://deeplinker.bio/.well-known/genid/1ef911be-b73f-3aee-99a2-046342615d46\n",
      "hash://sha256/d981008d7c7dddd827bcba16087a9c88cf233567d4751f67bb7f96e0756f2c9c\thttp://www.w3.org/ns/prov#generatedAtTime\t2018-10-01T05:03:51.360Z\n",
      "hash://sha256/d981008d7c7dddd827bcba16087a9c88cf233567d4751f67bb7f96e0756f2c9c\thttp://www.w3.org/ns/prov#wasGeneratedBy\te871efcd-c2f9-4e8e-ac3a-bc45943c3e65\n",
      "hash://sha256/d981008d7c7dddd827bcba16087a9c88cf233567d4751f67bb7f96e0756f2c9c\thttp://purl.org/pav/previousVersion\thttps://deeplinker.bio/.well-known/genid/1ef911be-b73f-3aee-99a2-046342615d46\n",
      "cbe4cdda-2045-415c-8968-039e389b7fc7\thttp://www.w3.org/ns/prov#hadMember\thttp://ipt.gbifbenin.org/eml.do?r=cnsf_niger\n",
      "http://ipt.gbifbenin.org/eml.do?r=cnsf_niger\thttp://purl.org/dc/elements/1.1/format\tapplication/eml\n"
     ]
    }
   ],
   "source": [
    "for c in context: print(Triple.FromNQuad(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructed 201176 new lines containing 50294 new qualifedGenerations\n"
     ]
    }
   ],
   "source": [
    "url = None\n",
    "newLines = []\n",
    "context = []\n",
    "for i, nQuad in enumerate(allNQuads):\n",
    "    triple = Triple.FromNQuad(nQuad)\n",
    "    if (triple.subject.Type() == Value.Type.URL and\n",
    "        triple.verb == \"http://purl.org/pav/hasVersion\" and\n",
    "        triple.object.Type() == Value.Type.CONTENT\n",
    "    ):\n",
    "        # When a new key triple is encountered, process the triples associated with the previous one\n",
    "        if url and len(context) > 0:\n",
    "            newLines += MakeQualifiedGeneration(url, context, crawlUUID)\n",
    "\n",
    "        # Start collecting triples for the next URL\n",
    "        context = []\n",
    "        url = str(triple.subject)\n",
    "    context.append(nQuad)\n",
    "\n",
    "# Process the final URL\n",
    "newLines += MakeQualifiedGeneration(url, context, crawlUUID)\n",
    "\n",
    "numGenerations = len([x for x in newLines if \"qualifiedGeneration\" in x])\n",
    "print(\"Constructed %d new lines containing %d new qualifedGenerations\" % (len(newLines), numGenerations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<hash://sha256/3eff98d4b66368fd8d1f8fa1af6a057774d8a407a4771490beeb9e7add76f362> <http://www.w3.org/ns/prov#qualifiedGeneration> <51ae6992-25ac-4ba4-8ca0-2614d0951be7> .\n",
      "<51ae6992-25ac-4ba4-8ca0-2614d0951be7> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/ns/prov#Generation> .\n",
      "<51ae6992-25ac-4ba4-8ca0-2614d0951be7> <http://www.w3.org/ns/prov#activity> <e871efcd-c2f9-4e8e-ac3a-bc45943c3e65> .\n",
      "<51ae6992-25ac-4ba4-8ca0-2614d0951be7> <http://www.w3.org/ns/prov#used> <https://search.idigbio.org/v2/search/publishers> .\n",
      "<hash://sha256/d8abe764baa8807af8c8f5034157945937fdaec9002a7b975df429d7538c4897> <http://www.w3.org/ns/prov#qualifiedGeneration> <f5c1febc-53d9-41a2-8873-b6b09aa463ff> .\n",
      "<f5c1febc-53d9-41a2-8873-b6b09aa463ff> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/ns/prov#Generation> .\n",
      "<f5c1febc-53d9-41a2-8873-b6b09aa463ff> <http://www.w3.org/ns/prov#activity> <e871efcd-c2f9-4e8e-ac3a-bc45943c3e65> .\n",
      "<f5c1febc-53d9-41a2-8873-b6b09aa463ff> <http://www.w3.org/ns/prov#used> <https://api.gbif.org/v1/dataset> .\n",
      "<hash://sha256/edfb060806a88d77a889b8937104414ba021813939ccb025bd96adbb96239e26> <http://www.w3.org/ns/prov#qualifiedGeneration> <a21edc64-1857-43ef-aaa4-5e266a6b9e86> .\n",
      "<a21edc64-1857-43ef-aaa4-5e266a6b9e86> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/ns/prov#Generation> .\n",
      "<a21edc64-1857-43ef-aaa4-5e266a6b9e86> <http://www.w3.org/ns/prov#activity> <e871efcd-c2f9-4e8e-ac3a-bc45943c3e65> .\n",
      "<a21edc64-1857-43ef-aaa4-5e266a6b9e86> <http://www.w3.org/ns/prov#used> <https://bms.gfbio.org/services/data-sources/> .\n",
      "<hash://sha256/23bb9f821b8666ae30a298c1b6626c1acd659d3c82ff08f006448fd3d47c01bd> <http://www.w3.org/ns/prov#qualifiedGeneration> <5288728c-f420-4d73-b9c6-2c81cd6c1e30> .\n",
      "<5288728c-f420-4d73-b9c6-2c81cd6c1e30> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/ns/prov#Generation> .\n",
      "<5288728c-f420-4d73-b9c6-2c81cd6c1e30> <http://www.w3.org/ns/prov#activity> <e871efcd-c2f9-4e8e-ac3a-bc45943c3e65> .\n",
      "<5288728c-f420-4d73-b9c6-2c81cd6c1e30> <http://www.w3.org/ns/prov#used> <https://www.morphosource.org/rss/ms.rss> .\n",
      "<hash://sha256/72a78747b822a861abd4bb4e1af1e250a2521c6f070c60308eb0a9d18fafdf00> <http://www.w3.org/ns/prov#qualifiedGeneration> <2a9b9091-4af0-457d-a5d7-d70f13466db2> .\n",
      "<2a9b9091-4af0-457d-a5d7-d70f13466db2> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/ns/prov#Generation> .\n",
      "<2a9b9091-4af0-457d-a5d7-d70f13466db2> <http://www.w3.org/ns/prov#activity> <e871efcd-c2f9-4e8e-ac3a-bc45943c3e65> .\n",
      "<2a9b9091-4af0-457d-a5d7-d70f13466db2> <http://www.w3.org/ns/prov#used> <http://portal.torcherbaria.org/portal/webservices/dwc/rss.xml> .\n",
      "<https://deeplinker.bio/.well-known/genid/d37897af-ecfa-376c-a57d-4f42093e11a3> <http://www.w3.org/ns/prov#qualifiedGeneration> <f4ed7ec7-56fe-4fe7-875c-166b501dc4c6> .\n",
      "<f4ed7ec7-56fe-4fe7-875c-166b501dc4c6> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/ns/prov#Generation> .\n",
      "<f4ed7ec7-56fe-4fe7-875c-166b501dc4c6> <http://www.w3.org/ns/prov#activity> <e871efcd-c2f9-4e8e-ac3a-bc45943c3e65> .\n",
      "<f4ed7ec7-56fe-4fe7-875c-166b501dc4c6> <http://www.w3.org/ns/prov#used> <http://hymfiles.biosci.ohio-state.edu:8080/ipt/rss.do> .\n",
      "<hash://sha256/cc5a11eefbdb50291456c09cba0909e65e3f04a49e70735b9face57db269570b> <http://www.w3.org/ns/prov#qualifiedGeneration> <1f56ed35-dfdd-4543-8dfb-dfad7f1664d3> .\n",
      "<1f56ed35-dfdd-4543-8dfb-dfad7f1664d3> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/ns/prov#Generation> .\n",
      "<1f56ed35-dfdd-4543-8dfb-dfad7f1664d3> <http://www.w3.org/ns/prov#activity> <e871efcd-c2f9-4e8e-ac3a-bc45943c3e65> .\n",
      "<1f56ed35-dfdd-4543-8dfb-dfad7f1664d3> <http://www.w3.org/ns/prov#used> <https://invertnet.org/idigbio-feed/rss.php> .\n",
      "<https://deeplinker.bio/.well-known/genid/75652a15-354f-3dcd-9a4d-26437b85d42d> <http://www.w3.org/ns/prov#qualifiedGeneration> <e77e5289-d46e-42ad-b157-f5f90b168e6d> .\n",
      "<e77e5289-d46e-42ad-b157-f5f90b168e6d> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/ns/prov#Generation> .\n",
      "<e77e5289-d46e-42ad-b157-f5f90b168e6d> <http://www.w3.org/ns/prov#activity> <e871efcd-c2f9-4e8e-ac3a-bc45943c3e65> .\n",
      "<e77e5289-d46e-42ad-b157-f5f90b168e6d> <http://www.w3.org/ns/prov#used> <http://iptmuse.colorado.edu:8080/ipt/rss.do> .\n",
      "<hash://sha256/d5e5a1e43eb44a80de645190dfeef88cc33e6719a3374a06d1c066899f970cfb> <http://www.w3.org/ns/prov#qualifiedGeneration> <520fa934-91d5-48c7-9cdd-6e62cdaddc8a> .\n",
      "<520fa934-91d5-48c7-9cdd-6e62cdaddc8a> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/ns/prov#Generation> .\n",
      "<520fa934-91d5-48c7-9cdd-6e62cdaddc8a> <http://www.w3.org/ns/prov#activity> <e871efcd-c2f9-4e8e-ac3a-bc45943c3e65> .\n",
      "<520fa934-91d5-48c7-9cdd-6e62cdaddc8a> <http://www.w3.org/ns/prov#used> <http://dmitriev.speciesfile.org/Export/rss.xml> .\n",
      "<hash://sha256/5a411ad25a1deec9a0785cdc1cbbfdf60d45016973a17a454aee4965819442ac> <http://www.w3.org/ns/prov#qualifiedGeneration> <4070f320-054a-41f3-bcd6-d47c089636c9> .\n",
      "<4070f320-054a-41f3-bcd6-d47c089636c9> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/ns/prov#Generation> .\n",
      "<4070f320-054a-41f3-bcd6-d47c089636c9> <http://www.w3.org/ns/prov#activity> <e871efcd-c2f9-4e8e-ac3a-bc45943c3e65> .\n",
      "<4070f320-054a-41f3-bcd6-d47c089636c9> <http://www.w3.org/ns/prov#used> <https://botanydb.colorado.edu/webservices/dwc/rss.xml> .\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "for x in newLines[:40]: print(x)\n",
    "print(\"...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
